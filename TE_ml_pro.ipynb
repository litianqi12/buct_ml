{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 前一步已经确认随机森林效果最优\n",
    "改进"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集大小: (10132, 52), 测试集大小: (21120, 52)\n",
      "训练集类别分布: {np.int64(0): np.int64(52), np.int64(1): np.int64(480), np.int64(2): np.int64(480), np.int64(3): np.int64(480), np.int64(4): np.int64(480), np.int64(5): np.int64(480), np.int64(6): np.int64(480), np.int64(7): np.int64(480), np.int64(8): np.int64(480), np.int64(9): np.int64(480), np.int64(10): np.int64(480), np.int64(11): np.int64(480), np.int64(12): np.int64(480), np.int64(13): np.int64(480), np.int64(14): np.int64(480), np.int64(15): np.int64(480), np.int64(16): np.int64(480), np.int64(17): np.int64(480), np.int64(18): np.int64(480), np.int64(19): np.int64(480), np.int64(20): np.int64(480), np.int64(21): np.int64(480)}\n",
      "测试集类别分布: {np.int64(0): np.int64(960), np.int64(1): np.int64(960), np.int64(2): np.int64(960), np.int64(3): np.int64(960), np.int64(4): np.int64(960), np.int64(5): np.int64(960), np.int64(6): np.int64(960), np.int64(7): np.int64(960), np.int64(8): np.int64(960), np.int64(9): np.int64(960), np.int64(10): np.int64(960), np.int64(11): np.int64(960), np.int64(12): np.int64(960), np.int64(13): np.int64(960), np.int64(14): np.int64(960), np.int64(15): np.int64(960), np.int64(16): np.int64(960), np.int64(17): np.int64(960), np.int64(18): np.int64(960), np.int64(19): np.int64(960), np.int64(20): np.int64(960), np.int64(21): np.int64(960)}\n",
      "原始训练集大小: (10132, 52), 增强后训练集大小: (10560, 52)\n"
     ]
    }
   ],
   "source": [
    "# 导入必要的库\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.naive_bayes import GaussianNB  # 导入朴素贝叶斯算法\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import time\n",
    "\n",
    "\n",
    "# 加载数据函数，加载指定文件夹内的数据文件，并按顺序合并\n",
    "def load_te_data(folder_path):\n",
    "    data = []  # 存储数据\n",
    "    labels = []  # 存储标签\n",
    "    files = sorted(os.listdir(folder_path))  # 保证文件顺序一致\n",
    "    for file in files:\n",
    "        if file.endswith('.dat'):  # 只处理以 '.dat' 结尾的文件\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            # 读取文件，假设是空格分隔的数据\n",
    "            df = pd.read_csv(file_path, sep='\\\\s+', header=None)\n",
    "            # 提取标签（假设标签位于文件名中）\n",
    "            label = int(file[1:3])  # 从文件名中提取标签，例如 'd00.dat' 提取 '00'\n",
    "            data.append(df)  # 添加数据\n",
    "            labels.append(np.full((df.shape[0],), label))  # 添加对应的标签\n",
    "    # 合并所有数据和标签\n",
    "    return pd.concat(data, axis=0), np.concatenate(labels, axis=0)\n",
    "\n",
    "# 加载训练集和测试集数据\n",
    "train_data, train_labels = load_te_data('TE_train')\n",
    "test_data, test_labels = load_te_data('TE_test')\n",
    "\n",
    "# 将标签添加到数据中，方便后续操作\n",
    "train_data['Label'] = train_labels\n",
    "test_data['Label'] = test_labels\n",
    "\n",
    "# 确保训练集和测试集特征对齐，去除标签列进行对比\n",
    "common_columns = train_data.columns.intersection(test_data.columns).drop('Label')\n",
    "train_data = train_data[common_columns.to_list() + ['Label']]\n",
    "test_data = test_data[common_columns.to_list() + ['Label']]\n",
    "\n",
    "# 数据标准化：为了后续模型训练，确保特征具有相同的尺度\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(train_data.drop('Label', axis=1))  # 训练集特征标准化\n",
    "X_test = scaler.transform(test_data.drop('Label', axis=1))  # 测试集特征标准化\n",
    "y_train = train_data['Label'].values  # 训练集标签\n",
    "y_test = test_data['Label'].values  # 测试集标签\n",
    "\n",
    "# 输出训练集和测试集的大小\n",
    "print(f\"训练集大小: {X_train.shape}, 测试集大小: {X_test.shape}\")\n",
    "# 定义函数检查类别分布\n",
    "def check_class_distribution(y_train, y_test):\n",
    "    unique_train, counts_train = np.unique(y_train, return_counts=True)  # 训练集类别分布\n",
    "    unique_test, counts_test = np.unique(y_test, return_counts=True)  # 测试集类别分布\n",
    "    print(\"训练集类别分布:\", dict(zip(unique_train, counts_train)))\n",
    "    print(\"测试集类别分布:\", dict(zip(unique_test, counts_test)))\n",
    "\n",
    "# 检查训练集和测试集的类别分布\n",
    "check_class_distribution(y_train, y_test)\n",
    "\n",
    "# 如果训练集类别不平衡，使用 SMOTE 技术进行过采样\n",
    "smote = SMOTE(random_state=42)  # 初始化 SMOTE 对象\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)  # 对训练集进行过采样\n",
    "\n",
    "# 输出过采样前后的训练集大小\n",
    "print(f\"原始训练集大小: {X_train.shape}, 增强后训练集大小: {X_train_resampled.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练并评估模型的函数\n",
    "def train_and_evaluate(model, X_train, y_train, X_test, y_test, model_name, track_loss=False):\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    # 预测\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # 计算指标\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    # 混淆矩阵\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # 保存分类报告到txt文件\n",
    "    report = classification_report(y_test, y_pred, zero_division=0)\n",
    "    with open(f\"test_{model_name}_classification_report.txt\", \"w\") as f:\n",
    "        f.write(f\"classification_report ({model_name}):\\n\")\n",
    "        f.write(report)  # 保存报告内容\n",
    "\n",
    "\n",
    "    # 返回结果\n",
    "    return {\n",
    "        \"model_name\": model_name,\n",
    "        \"train_time\": train_time,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1,\n",
    "        \"conf_matrix\": conf_matrix,\n",
    "    }\n",
    "\n",
    "# 初始化模型（加权分类器处理类别不平衡）\n",
    "rf = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)\n",
    "\n",
    "# 训练并评估模型\n",
    "results = []\n",
    "for model, name in zip([rf], [\"Random Forest\"]):\n",
    "    result = train_and_evaluate(model, X_train, y_train, X_test, y_test, name)\n",
    "    results.append(result)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 修改开始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "选择的特征数: 26\n"
     ]
    }
   ],
   "source": [
    "# 训练一个随机森林来评估特征重要性\n",
    "rf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# 获取特征重要性\n",
    "feature_importances = rf.feature_importances_\n",
    "\n",
    "# 选择重要性较高的特征（例如选择前50%最重要的特征）\n",
    "threshold = np.percentile(feature_importances, 50)\n",
    "selected_features = np.where(feature_importances >= threshold)[0]\n",
    "\n",
    "# 只保留选定的特征\n",
    "X_train_selected = X_train_resampled[:, selected_features]\n",
    "X_test_selected = X_test[:, selected_features]\n",
    "\n",
    "print(f\"选择的特征数: {X_train_selected.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with SMOTE 准确率: 0.5345\n",
      "Random Forest with PCA 准确率: 0.1758\n",
      "Random Forest with Feature Selection 准确率: 0.5006\n",
      "Random Forest with RFE 准确率: 0.4961\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA  # 导入主成分分析（PCA）降维工具\n",
    "from sklearn.feature_selection import RFE  # 导入递归特征消除（RFE）工具\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 训练并评估模型的函数\n",
    "def train_and_evaluate(model, X_train, y_train, X_test, y_test, model_name):\n",
    "    start_time = time.time()\n",
    "    # 训练模型\n",
    "    model.fit(X_train, y_train)\n",
    "    train_time = time.time() - start_time\n",
    "    # 使用训练好的模型进行预测\n",
    "    y_pred = model.predict(X_test)\n",
    "    # 准确率\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{model_name} 准确率: {accuracy:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        \"model_name\": model_name,\n",
    "        \"train_time\": train_time,\n",
    "        \"accuracy\": accuracy\n",
    "    }\n",
    "\n",
    "# 初始化随机森林模型\n",
    "rf = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)\n",
    "\n",
    "# 1. 原始数据（使用SMOTE）\n",
    "results_original = []\n",
    "result_original = train_and_evaluate(rf, X_train_resampled, y_train_resampled, X_test, y_test, \"Random Forest with SMOTE\")\n",
    "results_original.append(result_original)\n",
    "\n",
    "# 2. PCA降维，保留95%的方差信息\n",
    "pca = PCA(n_components=0.95)\n",
    "X_train_pca = pca.fit_transform(X_train_resampled)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# 训练并评估降维后的随机森林模型\n",
    "results_pca = []\n",
    "result_pca = train_and_evaluate(rf, X_train_pca, y_train_resampled, X_test_pca, y_test, \"Random Forest with PCA\")\n",
    "results_pca.append(result_pca)\n",
    "\n",
    "# 3. 基于特征重要性的特征选择\n",
    "rf_feature_selector = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)\n",
    "rf_feature_selector.fit(X_train_resampled, y_train_resampled)  # 训练随机森林模型\n",
    "# 获取每个特征的特征重要性分数\n",
    "importances = rf_feature_selector.feature_importances_\n",
    "# 按特征重要性分数对特征进行排序，从最重要到最不重要\n",
    "indices = np.argsort(importances)[::-1]\n",
    "# 选择前20个最重要的特征\n",
    "selected_features = indices[:20]\n",
    "# 提取出这些最重要的特征\n",
    "X_train_selected = X_train_resampled[:, selected_features]\n",
    "X_test_selected = X_test[:, selected_features]\n",
    "\n",
    "# 训练并评估仅使用最重要特征的随机森林模型\n",
    "results_selected = []\n",
    "result_selected = train_and_evaluate(rf, X_train_selected, y_train_resampled, X_test_selected, y_test, \"Random Forest with Feature Selection\")\n",
    "results_selected.append(result_selected) \n",
    "\n",
    "# 4. 使用RFE进行特征选择\n",
    "# 初始化一个线性SVM模型，用于RFE特征选择\n",
    "svm = SVC(kernel='linear', random_state=42)\n",
    "# 初始化RFE进行特征选择，选择20个最优特征\n",
    "rfe = RFE(svm, n_features_to_select=20)\n",
    "# 训练RFE选择最重要的特征\n",
    "rfe.fit(X_train_resampled, y_train_resampled)\n",
    "X_train_rfe = X_train_resampled[:, rfe.support_]  # 选出训练集中的重要特征\n",
    "X_test_rfe = X_test[:, rfe.support_]  # 选出测试集中的重要特征\n",
    "# 训练并评估使用RFE选出的特征的随机森林模型\n",
    "results_rfe = []\n",
    "result_rfe = train_and_evaluate(rf, X_train_rfe, y_train_resampled, X_test_rfe, y_test, \"Random Forest with RFE\")\n",
    "results_rfe.append(result_rfe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\86185\\Downloads\\anaconda3\\envs\\notebook\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:07:11] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier (RF + SVC + Logistic Regression + XGBoost) 准确率: 0.5843\n",
      "\n",
      "最终集成学习模型的准确率: 0.5843\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import xgboost as xgb\n",
    "import time\n",
    "\n",
    "# 加载数据函数，加载指定文件夹内的数据文件，并按顺序合并\n",
    "def load_te_data(folder_path):\n",
    "    data = []  # 存储所有数据的列表\n",
    "    labels = []  # 存储所有标签的列表\n",
    "    files = sorted(os.listdir(folder_path))  # 获取文件夹中的所有文件，并按字母顺序排序\n",
    "    for file in files:\n",
    "        if file.endswith('.dat'):  # 只处理以 '.dat' 结尾的文件\n",
    "            file_path = os.path.join(folder_path, file)  # 获取文件的完整路径\n",
    "            # 读取文件，假设文件内容是空格分隔的数值数据\n",
    "            df = pd.read_csv(file_path, sep='\\\\s+', header=None)  # 使用 pandas 读取数据\n",
    "            # 从文件名中提取标签（假设标签位于文件名的第2和第3个字符位置）\n",
    "            label = int(file[1:3])  # 例如 'd00.dat' 提取 '00' 作为标签\n",
    "            data.append(df)  # 将读取的数据添加到 data 列表\n",
    "            labels.append(np.full((df.shape[0],), label))  # 将对应的标签填充为与数据行数相同的数组，并添加到 labels 列表\n",
    "    # 合并所有的数据和标签，返回一个 DataFrame 和一个包含标签的 numpy 数组\n",
    "    return pd.concat(data, axis=0), np.concatenate(labels, axis=0)\n",
    "\n",
    "# 加载训练集和测试集数据\n",
    "train_data, train_labels = load_te_data('TE_train')  # 加载训练数据\n",
    "test_data, test_labels = load_te_data('TE_test')  # 加载测试数据\n",
    "\n",
    "# 将标签添加到数据中，方便后续操作\n",
    "train_data['Label'] = train_labels  # 将标签列添加到训练集数据中\n",
    "test_data['Label'] = test_labels  # 将标签列添加到测试集数据中\n",
    "\n",
    "# 确保训练集和测试集特征对齐，去除标签列进行对比\n",
    "common_columns = train_data.columns.intersection(test_data.columns).drop('Label')  # 找出两者公共的特征列（去掉标签列）\n",
    "# 重新调整训练集和测试集的数据，确保特征列一致\n",
    "train_data = train_data[common_columns.to_list() + ['Label']]  # 选择公共特征列和标签列\n",
    "test_data = test_data[common_columns.to_list() + ['Label']]  # 选择公共特征列和标签列\n",
    "\n",
    "# 数据标准化：为了后续模型训练，确保特征具有相同的尺度\n",
    "scaler = StandardScaler()  # 初始化标准化处理器\n",
    "X_train = scaler.fit_transform(train_data.drop('Label', axis=1))  # 训练集特征标准化（去除标签列）\n",
    "X_test = scaler.transform(test_data.drop('Label', axis=1))  # 测试集特征标准化（去除标签列）\n",
    "y_train = train_data['Label'].values  # 获取训练集标签\n",
    "y_test = test_data['Label'].values  # 获取测试集标签\n",
    "\n",
    "# SMOTE处理类别不平衡：对训练集进行过采样，平衡各类别样本数\n",
    "smote = SMOTE(random_state=42)  # 初始化 SMOTE 对象\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)  # 进行过采样，返回新的训练集数据和标签\n",
    "\n",
    "# 训练并评估模型的函数\n",
    "def train_and_evaluate(model, X_train, y_train, X_test, y_test, model_name):\n",
    "    start_time = time.time() \n",
    "    model.fit(X_train, y_train) \n",
    "    train_time = time.time() - start_time \n",
    "    # 进行预测\n",
    "    y_pred = model.predict(X_test)\n",
    "    # 准确率\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{model_name} 准确率: {accuracy:.4f}\")\n",
    "    return {\n",
    "        \"model_name\": model_name,\n",
    "        \"train_time\": train_time,\n",
    "        \"accuracy\": accuracy\n",
    "    }\n",
    "\n",
    "# 初始化基础分类器\n",
    "rf = RandomForestClassifier(n_estimators=200, class_weight='balanced', random_state=42)  # 随机森林\n",
    "svc = SVC(kernel='linear', probability=True, random_state=42)  # 支持向量机\n",
    "log_reg = LogisticRegression(class_weight='balanced', random_state=42)  # 逻辑回归\n",
    "xgb_model = xgb.XGBClassifier(n_estimators=100, scale_pos_weight=10, use_label_encoder=False, eval_metric='mlogloss', random_state=42)  # XGBoost\n",
    "\n",
    "# 初始化集成学习模型（Soft Voting）\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('rf', rf),  # 随机森林\n",
    "    ('svc', svc),  # 支持向量机\n",
    "    ('log_reg', log_reg),  # 逻辑回归\n",
    "    ('xgb', xgb_model)  # XGBoost\n",
    "], voting='soft')  # 使用软投票策略\n",
    "\n",
    "# 训练并评估集成模型\n",
    "result_voting = train_and_evaluate(voting_clf, X_train_resampled, y_train_resampled, X_test, y_test, \"Voting Classifier (RF + SVC + Logistic Regression + XGBoost)\")\n",
    "\n",
    "print(f\"\\n最终集成学习模型的准确率: {result_voting['accuracy']:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
